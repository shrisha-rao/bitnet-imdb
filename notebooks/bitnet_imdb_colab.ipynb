{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrisha-rao/bitnet-imdb/blob/main/notebooks/bitnet_imdb_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYMVd_XxRjUa"
      },
      "source": [
        "# Fine-tune a BitNet Model on IMDB\n",
        "This notebook converts a small pretrained model (`bert-tiny`) into a **BitNet** with ternary weights and fine-tunes it on IMDB sentiment classification. It demonstrates:\n",
        "- Custom `BitLinear` layer with weight quantization and straight-through estimator.\n",
        "- Replacing all linear layers in a transformer.\n",
        "- Fine-tuning with Hugging Face `Trainer`.\n",
        "\n",
        "**Note:** Use a GPU runtime (Runtime → Change runtime type → T4 GPU) for faster training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ_kwUMqRjUe",
        "outputId": "6907ff26-c910-4ecf-8520-6768293930d5"
      },
      "source": [
        "# Install dependencies\n",
        "!pip install transformers datasets accelerate scikit-learn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.24.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.24.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.10.0+cu128)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.3.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=2.0.0->accelerate) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (0.24.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjg9FxNTSXLw",
        "outputId": "1b9e91da-0a5e-4c0d-f027-d152103929d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-5.2.0-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.24.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.24.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.3.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (0.24.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n",
            "Downloading transformers-5.2.0-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 5.0.0\n",
            "    Uninstalling transformers-5.0.0:\n",
            "      Successfully uninstalled transformers-5.0.0\n",
            "Successfully installed transformers-5.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "509Ma8HYTBXi",
        "outputId": "c571e126-f064-4d2e-d7b9-96440855ed64",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GwmB7Q0RjUf"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ7webftRjUg"
      },
      "source": [
        "## Define BitLinear Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AM-COcHRjUg"
      },
      "source": [
        "class BitLinear(nn.Linear):\n",
        "    def quantize_weights(self):\n",
        "        w = self.weight\n",
        "        alpha = w.abs().mean().clamp(min=1e-8)\n",
        "        ternary = torch.where(w > 0.5 * alpha, alpha, torch.where(w < -0.5 * alpha, -alpha, 0.0))\n",
        "        return ternary\n",
        "\n",
        "    def forward(self, x):\n",
        "        quantized_w = self.quantize_weights()\n",
        "        w_ste = self.weight + (quantized_w - self.weight).detach()\n",
        "        return F.linear(x, w_ste, self.bias)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMIjAhSJRjUg"
      },
      "source": [
        "## Replace Linear Layers in Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFZyLtYzRjUh"
      },
      "source": [
        "def replace_linear_with_bitlinear(model):\n",
        "    for name, child in model.named_children():\n",
        "        if isinstance(child, nn.Linear) and name != 'classifier':\n",
        "            new_layer = BitLinear(child.in_features, child.out_features, bias=child.bias is not None)\n",
        "            new_layer.weight.data = child.weight.data.clone()\n",
        "            if child.bias is not None:\n",
        "                new_layer.bias.data = child.bias.data.clone()\n",
        "            setattr(model, name, new_layer)\n",
        "        else:\n",
        "            replace_linear_with_bitlinear(child)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9_8N6NiRjUh"
      },
      "source": [
        "## Load Dataset and Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946,
          "referenced_widgets": [
            "2c989fb572414793b5b85fd8b40ac280",
            "f33cf2ce5c3848909cafab4a93965b7a",
            "d9c200b9ea9147dc9bf4d2268b9bab50",
            "0ea785bb35964596b1bbd562bd8164a8",
            "421513dcca0b4cac852559f155c2da4e",
            "fab4b25df3ff4ac580e8c5c0902cd576",
            "0f2c24081c234fc9b816fab5712a41eb",
            "3f970ffa591f4d2599fcfffcf647c1ed",
            "6eb53dc8fb1b4dfda1a5da301ebc43f0",
            "30b0f9ca3e134df68aa972d491930750",
            "a8b3e072be644467b631d605dec004aa",
            "59231ec460c44ad7b35365013063bbb5",
            "995cf21b15e44f64aef574cd134abff4",
            "e9bddcccc60a4691811cc9b049a06c50",
            "3d9a764058db40ebb50d45f5cca4e44b",
            "7bff237c384a4b0e90119b0051dc8b1a",
            "fbf3bed3a9fb4769a33ba70e8051d2f0",
            "a774261dea05499ebd22fd484376ec72",
            "cbc3871416914d538041bb787eb49023",
            "f172a839a949408782492df3a91d9921",
            "781276caf1ed4283ad43907008d4eca5",
            "97f6b790378d4c00a37d79010f28479c",
            "6ce0f34279b34e88b74d1b0862e4e272",
            "c025ffff1500436a9a5ff9c2f68a19c1",
            "652dd6394ecd4652876bdc7346ec2db2",
            "0f46d90155624c20b20513ebf19049d2",
            "340cd7dd92a0488ab41364036784ad71",
            "f9b59a1448e945b7a0d0c1e540161c68",
            "69c7217abafc4847acd108fb09e7a299",
            "61ded6cb91ee49db8db4d83b2bc90c5e",
            "d19fdac52c72493daf81f1ab6d7cfa4d",
            "1277eec462b04829aef76fd1579d6230",
            "5ec672b2ed5a4a6bbffd5ecd7bfc7518",
            "6acd5d32be664231a2b48614fc13ac76",
            "c5be2da23d974c87824fcdfad1fa8094",
            "7999038699e74cd0ba4155aba41058d6",
            "2ddc2ff87cf24dc4addb8ca751b8ea6b",
            "08142b160a7c40769b59542f2db43036",
            "5f74bbdd5d834d3683592c7b90b0a950",
            "357f0e4b66be499fa255b8ffb4220979",
            "134c5ee7a7874db7b36cf3a62a32bc09",
            "e48b2cbe662c43748994dd5adf25f550",
            "d020b4c0bfc54b289b6edd39bfb649ee",
            "0f674052f13e410a9dea3d9322353034",
            "e486d2f9ad684940964b980bdf8dd5be",
            "a2322968ce8a4593987dcb03eb0db8b3",
            "e9a95f37df5f45cc92d61d0288ea298f",
            "85fab61c4a094610aaafb3ea8d778786",
            "4d22daa0b825493d81b31ee456156bce",
            "7c574072fb004788b279b71b6aba6587",
            "13b883092a8d479591195121c4d7fbde",
            "b164e9d87e1c4e4e9b4922f81419a26c",
            "21835b5ae0cc496faf1f6a913f13618d",
            "6a3c634033094a4f8476b132ff96410d",
            "595e0e7d070a490dbeb87161f2c10474",
            "e06305410ea14581ab11302add9cd2c1",
            "fb2bdd21984d46aeabd8d486fc478bd5",
            "99298e0f83f149848a7ca82f861342fe",
            "241ba4349d7f46d49a84be4f2c768720",
            "36bb4a4a470045958cdff99b65c48641",
            "5606a6a5186f46e4b7dcd9d5acc24ab9",
            "83f9cd3d5cfd4126ad5e9354f5fbee5e",
            "36db7508c999460aa68c59559c207c29",
            "75ccd3ae9c4440bd91006eec8f577719",
            "ab51d487533742c5a0933089410dfedf",
            "214f7579ca4648a4adf2bad74726321a",
            "49c4cbf955964e58aead65a53709c42b",
            "50e55321777f486d8088bc8b11c52761",
            "d086eca805fe49d0b898ac9135fe9d27",
            "241c7b04e6924dfabf514cb9517332b5",
            "395162799e37419c8b20f5d9d06f91ff",
            "2b4d15640cba47d0b9526e5564d1fed3",
            "d09ab47ce8724774a22c9fe2b130f9e6",
            "06f4f58678674b94ba9b5ff1c857b643",
            "ba800263e53b461a8ac28b94ccb0299a",
            "690a25d823304f06afbd7f2c786408de",
            "0377b92e105e498495084e0bab05f36b",
            "997dd92aff014444bbc09406dba754e2",
            "6b9fc75dd5de4c2d9869f43a260de9ca",
            "c50a872fb263471186048650b4c9e8d8",
            "f7b8624c5e1e4bb9b3a1093bf1bb2de4",
            "81bdc2bd19454cdfa433579991dbe7db",
            "f4ac008627ee437ba84c06786a4cc09a",
            "495e52d36fd74245b289d217cc724d64",
            "ccdd2891e174479a8b168ece362bb081",
            "c37d549362984e6f96d8b2d0c05080c5",
            "dc92775c44d742dfafebf3eb1205363a",
            "5b738bb98fb848e1a1dbf198c7caca44",
            "8929d819fd64491bb08fed519341ef04",
            "3a09abfb87964b6ca7956c5f09023cf3",
            "700e856f4f64458d9bbc755f207ba2e8",
            "61c53f47185d4719b805c59d2021b116",
            "9bd7e5b808e349dd8309c81d6fd1f362",
            "e1f98316a20c474a9805cb195c975fc3",
            "34d9f1efaca647c9983e970d7321a694",
            "68f736e45666432bab222085c99a2d65",
            "a3c35dcc00e24b79b218200e36477aad",
            "4eed6151d57241a1a935e694bfbe0612",
            "9696525ac02242efb33908ff4ec2f886",
            "89e056e8ad514cd2a2bb4bc762874083",
            "0698e5b2d9224c60a8a4a8dde80b304a",
            "2cd750f3fe8949bdb4c673c344e0b3cc",
            "4fbace651a11412481a3ae2d40ebc4ea",
            "f3977311ffb2468a9b47392bc548c447",
            "d16fd00438e44a828a141dea09988174",
            "e27ca0d5feb2445dbaa5c92d96233a72",
            "ae372d89d1674c75ba10b308d89f7a61",
            "97d24af213134d89b41a5c9db906f1eb",
            "0f520b316e67483193a22b8563bca272",
            "699b11b71eb74b9a987befe47218d64a",
            "5675af17c7d44062bf9100b45c9f2c8b",
            "27b06e3eb5714a47ad197c3ffc3452ac",
            "866b598208674bdca6da7c7973b373ce",
            "02b63105c19241d0ae83fd8f7ebadbde",
            "43a8910f0c884d449c99d199c6b3fc1d",
            "c5cc7c98d2174faea41f7c53590dc9ed",
            "213376a1f20e47e9936ae8ed0dce54a6",
            "b1094dd5015e4bc38ba669d73bdac5b5",
            "c545de4bcc1b427ebc88a2ca4bc9ac61",
            "a3a42759ed1e4d619c875ba80c0e755f",
            "c1b3c00984254ecc93b0e7658d8daa76",
            "813107394429422492059090e2dc7ec1",
            "1bcbaeb3d2c44284b6bf07bb880a5d77",
            "43841408dcee4e4bafb14e0a3704c1e3",
            "47645c802d8046ff9cf30877d7f048eb",
            "a3dc3d1dfec44b8ebe58ee8ec134c8ca",
            "5c53723c14e84323ad48678f9dc46d7e",
            "58febce056ae4a5fb1f7f3ff6e4a4776",
            "994cf2235f1c43e2ab8546c0c79f8cc5",
            "34db0e59036a4f4e9555d5f5a6541947",
            "e4fadc7439f249449e98de1b007693e4",
            "2ccc457f4ed44b968a72631f8c41ae8c",
            "21a3c5c7cda84e89bfe96d1c7e56d5f8",
            "b34f2d5f329c46b5a62e3fb007661767",
            "47e619e61dbf42a49cf6d9554584ad3d",
            "c0a5ab40358f4132a04533e8f68d4f20",
            "f2fae675c6994cf19bd9e76f9caf33d1",
            "2ff62a0baa194e96af4131db48d37388",
            "d790504fe1a246b4bef8f78857ddfce3",
            "793803e3c3e84bc3a1e7702c6c1e176b",
            "28d1f3317802423892c5a7ed42c369a3",
            "f57e862a830845919bb59adf812c16e7",
            "5bb874fc8aaa4a61bbe504651657e17d",
            "75ca6837ea89424c92f9583780fc713a",
            "e4c87dab8faf4736ad1bc98eb9db7ea4",
            "cf04a361f1ef4622a26eece6d53c11d3",
            "0c5eb4d8c3054bc7a8c364022e4a0926",
            "ba08ed2c60974b268620a746085b9877",
            "c682f8ff39d847929be32ed0658646cb",
            "dc16193f994047fabc1d95c9554db173",
            "13ce42fb63af4c93b191cf0bff89c298",
            "5c887563f16b460ebfbb443ce63bd55c",
            "fab46d25100d4dc39c78333508ad03f0",
            "8dec4d4ffea74ad39f8eef699aab362c",
            "19933165d63d4f98b173502ac327b8ff",
            "4e76ce39dcbc41cb97b8e2688433a407",
            "f1c7cd58eefa4bdc9c477240e607521c",
            "f3a4fa0ca03b45b6aa74bc0c2c2fb2a4",
            "dca1d368744744a58cad6c44a952fbae",
            "95b3f0bf7c8c46728d8be3537e384f72",
            "997bbfbdbe63431c84cfcae75e93c6a1",
            "ef5aad166f674d17b0bf009c67921f65",
            "8d2c1638f29e4595ba8bc46f53872f35",
            "6c0e998502494a9dbb20a167d17b95ac",
            "b7323a79395141c3a6a70f6cd64b3364"
          ]
        },
        "id": "AcoUSUZcRjUi",
        "outputId": "c4de73e0-48f2-488a-ce4c-0157d31e7ef2",
        "collapsed": true
      },
      "source": [
        "# Load IMDB dataset (small subset for speed)\n",
        "dataset = load_dataset(\"imdb\")\n",
        "train_small = dataset[\"train\"].shuffle(seed=42).select(range(5000))\n",
        "test_small = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
        "\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"  # 67M params, still small and fast\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\",\n",
        "#                                           trust_remote_code=True)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True,\n",
        "                     max_length=512)\n",
        "\n",
        "tokenized_train = train_small.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_small.map(tokenize_function, batched=True)\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\",\n",
        "#                                                            num_labels=2)\n",
        "replace_linear_with_bitlinear(model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c989fb572414793b5b85fd8b40ac280"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59231ec460c44ad7b35365013063bbb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ce0f34279b34e88b74d1b0862e4e272"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6acd5d32be664231a2b48614fc13ac76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e486d2f9ad684940964b980bdf8dd5be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e06305410ea14581ab11302add9cd2c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49c4cbf955964e58aead65a53709c42b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "997dd92aff014444bbc09406dba754e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8929d819fd64491bb08fed519341ef04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89e056e8ad514cd2a2bb4bc762874083"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5675af17c7d44062bf9100b45c9f2c8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "813107394429422492059090e2dc7ec1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21a3c5c7cda84e89bfe96d1c7e56d5f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75ca6837ea89424c92f9583780fc713a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19933165d63d4f98b173502ac327b8ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mDistilBertForSequenceClassification LOAD REPORT\u001b[0m from: distilbert-base-uncased\n",
            "Key                     | Status     | \n",
            "------------------------+------------+-\n",
            "vocab_layer_norm.bias   | UNEXPECTED | \n",
            "vocab_projector.bias    | UNEXPECTED | \n",
            "vocab_transform.bias    | UNEXPECTED | \n",
            "vocab_layer_norm.weight | UNEXPECTED | \n",
            "vocab_transform.weight  | UNEXPECTED | \n",
            "pre_classifier.weight   | MISSING    | \n",
            "classifier.bias         | MISSING    | \n",
            "pre_classifier.bias     | MISSING    | \n",
            "classifier.weight       | MISSING    | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW7Hfq9fRjUi"
      },
      "source": [
        "## Define Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU_CvnieRjUi"
      },
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, predictions),\n",
        "        \"f1\": f1_score(labels, predictions, average=\"weighted\"),\n",
        "    }"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WD01nVqWSVvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuxKxIdyRjUi"
      },
      "source": [
        "## Training Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3erEvjYRjUi",
        "outputId": "7045fbff-9cdc-4531-977c-fb4ce5ca1d89"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`logging_dir` is deprecated and will be removed in v5.2. Please set `TENSORBOARD_LOGGING_DIR` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCBGsk_QRjUi"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248,
          "referenced_widgets": [
            "9d6ea40b2f9943d1b1aee1087b8c64a2",
            "bfb74f18d09d4b7badfc532cca7c8c9b",
            "e9ddfb9980b24660966b3d8226088a3d",
            "3572dc89282b40b998b249c7af80cb24",
            "47988225082f44bcbb97a40834c8d8f6",
            "c6ec9c6592fd4e8e8827851f52bf2b39",
            "5b1d4f6253d747369d20b64a1224c058",
            "4849d3843e8c4ea7a1b15ec627e59d02",
            "343b7c6240a94aff943b53dba2b83cba",
            "238941813ec84891905e7cc95f9a7ea7",
            "b60befb8522a47daae1bca56848d4d45"
          ]
        },
        "id": "NpOB5QvzRjUj",
        "outputId": "ec41e75b-dfe2-415d-ed42-8226107cc565"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [313/313 04:40, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.340793</td>\n",
              "      <td>0.844000</td>\n",
              "      <td>0.844022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d6ea40b2f9943d1b1aee1087b8c64a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias'].\n",
            "There were unexpected keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.beta', 'distilbert.embeddings.LayerNorm.gamma'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=313, training_loss=0.43188271811975837, metrics={'train_runtime': 282.5023, 'train_samples_per_second': 17.699, 'train_steps_per_second': 1.108, 'total_flos': 662336993280000.0, 'train_loss': 0.43188271811975837, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntRG4ub1RjUj"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hmspqC4RjUj",
        "outputId": "2530c5f8-b378-48f6-caa9-217bd1b43ab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e0ad6e5862504c30ac0c457264729ad7",
            "f8a1e9df8b544bd091dcff6a22353811",
            "b60c3add34f549c8a3c5a1710549a3c5",
            "0b6564c7adc84caeb760412239ff0fe0",
            "50f39317ffb84786980bfb974b1ce35b",
            "e09e07fd0dee4d4ca91739f98d2df79c",
            "fa076ac203734f7cb13e2d5b0862ac2e",
            "5f3183d0eb504a8e841b72c5c2d8d53c",
            "b3a5f9a4ef0b4eada4dc2ca7f77df3dc",
            "daf868c24a9845e287b8c146d826902b",
            "799bf7ceb4094847819e9db104b31d39"
          ]
        }
      },
      "source": [
        "model.save_pretrained(\"./bitnet-imdb-finetuned\")\n",
        "tokenizer.save_pretrained(\"./bitnet-imdb-finetuned\")\n",
        "\n",
        "# Zip and download (optional)\n",
        "import shutil\n",
        "from google.colab import files\n",
        "shutil.make_archive(\"bitnet-imdb-finetuned\", 'zip', \"./bitnet-imdb-finetuned\")\n",
        "files.download(\"bitnet-imdb-finetuned.zip\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0ad6e5862504c30ac0c457264729ad7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d4938c1e-d59f-4e94-a65b-4b44e37e1ac2\", \"bitnet-imdb-finetuned.zip\", 247196602)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPv5syzHRjUj"
      },
      "source": [
        "## Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBcoAgwsRjUj",
        "outputId": "975ea4a2-d44d-4eb0-ca93-ce7f49720695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "74fe8aeb99e441468f9d7db71ba2d2d9",
            "c88950024324497bb7e6c82c2ca53d82",
            "f8e7e4bbe25b4800a28af1801acaa190",
            "9603e27110b84c3f8c85e88e0788a664",
            "3bebbf34168c41dbb5562fd394dc702b",
            "3253b1d6949149c58ce0b0d9379dfa01",
            "ffccc7c896484fdd8c116f194b9dba7a",
            "debcf34174f04111a004fb437eb46bb5",
            "7618234da46d46e09129a88e04dea6de",
            "11f6ea968c3c4b27a28d1ebfe9b1cf94",
            "43b54a553aa64e1db9050ce24e5a885d"
          ]
        }
      },
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"text-classification\", model=\"./bitnet-imdb-finetuned\", tokenizer=\"./bitnet-imdb-finetuned\")\n",
        "print(classifier(\"This movie was absolutely wonderful!\"))\n",
        "print(classifier(\"Worst film ever made.\"))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/104 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74fe8aeb99e441468f9d7db71ba2d2d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_1', 'score': 0.983174741268158}]\n",
            "[{'label': 'LABEL_0', 'score': 0.9422519207000732}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uR-eGSjNR2Lk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}